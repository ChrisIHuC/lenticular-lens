[x] convert the rdf to tables
  - convert to ntriples
  - check for nodes without a type
  - extract all available columns per type
  - create DDL per type
  - load rdf into postgres

[x] get the marriage dataset
  - refine it using a sequence of views (the slow ones can be marked as materialized and refresh upon new data ingest)
    - every subject that
      - has type person
      - is not a child (target of the hasChild predicate) 
      - is not a couple (target of the isCouple predicate) 
      - doesn't have a name like '..., ...'
      - appears on a marriage record on a scan whose total count of records > 6
      - whose relation_info has a type that matches either "vrouw van", "zijn vrouw", "man van" (and a few more)
      - whose record's registry is in the 17th century
      - that's on a record where one of the persons has a name that occurs < 5 times

get dataset Baptism (filter out a bunch of records again)

and dataset Burial (filter out a bunch of records again)

get ecartico (not filtered)

link subjects within marriage on exact match of names
  refine them on having a record date within 50 years

link subjects within baptism on exact match of names
  refine them on having a record date within 50 years

link subjects within burial on exact match of names
  refine them on having a record date within 50 years


link it on some property (exact match of names) # You can use full python here

filter the links to those that also link on some other property (birthdates within some range)

filter out anything that is not linkable to ecartico



then we cluster (an algorithm in python based on the total unioned graph)

  - 3 million links results in 3000 clusters with a size of < 10 persons


 - baptism
 - marriage
 - burial
 - ecartico